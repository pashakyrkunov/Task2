{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import NormalPredictor\n",
    "from surprise import SVD\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import get_dataset_dir\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30\n",
    "n = 5\n",
    "threshold = 3.52\n",
    "measure = ['RMSE']\n",
    "test_rmse = 'test_rmse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x7fa9ce3b4730>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Dataset.load_builtin('ml-100k')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "define_algorithms = {\n",
    "    'NP': NormalPredictor(),\n",
    "    'KNN_cosine': KNNWithMeans(k = k, sim_options = { 'name': 'cosine' }),\n",
    "    'KNN_MSD': KNNWithMeans(k = k),\n",
    "    'KNN_pearson': KNNWithMeans(k = k, sim_options = { 'name': 'pearson' }),\n",
    "    'svd' : SVD()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5198  1.5234  1.5316  1.5048  1.5126  1.5184  0.0092  \n",
      "Fit time          0.09    0.12    0.12    0.12    0.12    0.11    0.01    \n",
      "Test time         0.16    0.10    0.15    0.15    0.10    0.13    0.03    \n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9443  0.9731  0.9587  0.9622  0.9594  0.9595  0.0092  \n",
      "Fit time          0.73    0.73    0.74    0.73    0.90    0.77    0.07    \n",
      "Test time         2.78    2.91    2.91    2.77    2.80    2.83    0.06    \n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9597  0.9478  0.9472  0.9641  0.9451  0.9528  0.0076  \n",
      "Fit time          0.29    0.35    0.45    0.31    0.30    0.34    0.06    \n",
      "Test time         2.68    2.83    3.13    2.50    2.47    2.72    0.24    \n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9540  0.9476  0.9522  0.9528  0.9510  0.9515  0.0022  \n",
      "Fit time          0.99    0.98    1.37    1.01    1.14    1.10    0.15    \n",
      "Test time         2.52    2.81    2.69    2.68    2.80    2.70    0.11    \n",
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9391  0.9284  0.9370  0.9372  0.9403  0.9364  0.0042  \n",
      "Fit time          4.50    4.32    4.33    4.42    4.35    4.39    0.07    \n",
      "Test time         0.20    0.18    0.10    0.23    0.10    0.16    0.05    \n"
     ]
    }
   ],
   "source": [
    "def crv_rsma(define_algorithms, data, measure, test_rmse):\n",
    "    rsma = {}\n",
    "    for [name, algorithm] in define_algorithms.items():\n",
    "        crv = cross_validate(algorithm, data, measures = measure, verbose=True)\n",
    "        rsma[name] = round(crv[test_rmse].mean(), 3)\n",
    "    return rsma\n",
    "\n",
    "rsma = crv_rsma(define_algorithms, data, measure, test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NP': 1.518,\n",
       " 'KNN_cosine': 0.96,\n",
       " 'KNN_MSD': 0.953,\n",
       " 'KNN_pearson': 0.951,\n",
       " 'svd': 0.936}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'svd'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestalgo_name = min(rsma.items(), key=lambda x: x[1])[0]\n",
    "bestalgo = define_algorithms[bestalgo_name]\n",
    "bestalgo_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate precision@k and recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k = 10, threshold = 3.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestalgo.fit(trainset)\n",
    "predictions = bestalgo.test(testset)\n",
    "precisions, recalls = precision_recall_at_k(predictions, k = 5, threshold = threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.731"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisionak = round(sum(precision for precision in precisions.values()) / len(precisions), 3)\n",
    "precisionak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.362"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recallak = round(sum(recall for recall in recalls.values()) / len(recalls), 3)\n",
    "recallak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommended_items(top_n, user):\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        if uid == user: \n",
    "            items = [iid for (iid, _) in user_ratings]\n",
    "            rate = user_ratings\n",
    "            break\n",
    "    return rate, items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_info(items):\n",
    "    data_path = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    info = {}\n",
    "    data = pd.read_csv(data_path, sep='|',encoding='ISO-8859-1', header = None) \n",
    "    for i in items:\n",
    "        row = data.iloc[int(i)]\n",
    "        info[i] = (row[1], row[2])\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['189', '483', '165', '169', '15']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = trainset.build_anti_testset()\n",
    "predictions = bestalgo.test(testset)\n",
    "top_n = get_top_n(predictions, n)\n",
    "\n",
    "user = '20'\n",
    "rate, films = recommended_items(top_n, user)\n",
    "rate=dict(rate)\n",
    "films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'189': ('Henry V (1989)', '01-Jan-1989'),\n",
       " '483': ('Maltese Falcon, The (1941)', '01-Jan-1941'),\n",
       " '165': ('Manon of the Spring (Manon des sources) (1986)', '01-Jan-1986'),\n",
       " '169': ('Cinema Paradiso (1988)', '01-Jan-1988'),\n",
       " '15': ('French Twist (Gazon maudit) (1995)', '01-Jan-1995')}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = items_info(films)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_to_file(user, info, rate):\n",
    "    file = open('recsys_2_2.txt', 'w')\n",
    "    file.write('User '+ user + '\\n')\n",
    "    for i in info:\n",
    "        file.write(str(i) + ' ' + str(info[i]) + ' ' + str(round(rate[i],3)) + '\\n')\n",
    "    file.close()\n",
    "    \n",
    "writing_to_file(user, info, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
